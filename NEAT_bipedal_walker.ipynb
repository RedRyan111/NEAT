{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "from random import choice\n",
    "import math\n",
    "import gym\n",
    "import copy\n",
    "import time\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = 'C:\\\\Users\\\\raven\\\\NEAT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graphs(num_models,num_inp,num_out):\n",
    "    for i in range(num_models):\n",
    "        #remove all files in Graph_folder\n",
    "        if(os.getcwd()+'\\\\Graph_folder' in [x[0] for x in os.walk(os.getcwd())]):\n",
    "            shutil.rmtree(os.getcwd()+'\\\\Graph_folder\\\\')\n",
    "\n",
    "        #create new file\n",
    "        os.mkdir(os.getcwd()+'\\\\Graph_folder\\\\')\n",
    "        \n",
    "        #create number of files needed\n",
    "        for i in range(num_models):\n",
    "            fh=open(os.getcwd()+\"\\\\Graph_folder\\\\model_\"+str(i)+\".edgelist\", \"x\")\n",
    "            fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph(model_num,num_inp,num_out):\n",
    "    fh=open(os.getcwd()+\"\\\\Graph_folder\\\\model_\"+str(model_num)+\".edgelist\", \"rb\")\n",
    "    G = nx.read_edgelist(fh,nodetype=int,create_using=nx.DiGraph(),data=(('weight',float),('activation',int),('inn_num',int)))\n",
    "    fh.close() \n",
    "    \n",
    "    #add input and output nodes\n",
    "    for i in range(num_inp+num_out):\n",
    "        G.add_node(i)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_graph(model,model_num):\n",
    "    nx.write_edgelist(model, os.getcwd()+\"\\\\Graph_folder\\\\model_\"+str(model_num)+\".edgelist\",data=['weight','activation','inn_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(gene_model,num_models,max_inn_num,model_num):\n",
    "    new_con_prob = .5\n",
    "    con_to_node_prob = .2\n",
    "    change_weights = .8\n",
    "    \n",
    "    if(random.random() < new_con_prob):\n",
    "        add_con(gene_model,num_models,max_inn_num,model_num)\n",
    "        \n",
    "    if(random.random() < con_to_node_prob):\n",
    "        con_to_node(gene_model,num_models,max_inn_num,model_num)\n",
    "    \n",
    "    if(random.random() < change_weights):\n",
    "        new_weight(gene_model,model_num)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_con(model,num_models,max_inn_num,model_num):\n",
    "    node_list = list(model.nodes)\n",
    "    \n",
    "    #get two random nodes that aren't the same, try this 5 times when failed\n",
    "    length = len(node_list)\n",
    "    node1 = node_list[random.randint(0,length-1)]\n",
    "    try_amt = 5\n",
    "    node2 = 0\n",
    "    for i in range(try_amt):\n",
    "        node2 = node_list[random.randint(num_out,length-1)]\n",
    "        if( (node2<num_inp) or (node1>=num_inp and node1<num_inp+num_out) or (node1 == node2)):\n",
    "            if(i==try_amt-1):\n",
    "                return 0\n",
    "            else: \n",
    "                continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    #check if adding edge will cause loop\n",
    "    if(check_edges(model,node1,node2)):\n",
    "        model.add_edge(node1,node2,weight=random.random(),activation=1,inn_num=inn_num((node1,node2),num_models,max_inn_num))\n",
    "        max_inn_num[0]+=1\n",
    "        \n",
    "    #save model\n",
    "    write_graph(model,model_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_to_node(model,num_models,max_inn_num,model_num):\n",
    "    #if no connections, dont run rest of function\n",
    "    temp = list(model.edges())\n",
    "    if(len(temp)==0):\n",
    "        return 0\n",
    "    \n",
    "    node1,node2 = temp[random.randint(0,len(temp)-1)]\n",
    "\n",
    "    new_node = max(list(model.nodes))+1\n",
    "\n",
    "    w1 = 1\n",
    "    w2 = nx.get_edge_attributes(model,'weight').get((node1,node2))\n",
    "\n",
    "    model.add_edge(node1,new_node,weight=w1,activation=1)\n",
    "    model.add_edge(new_node,node2,weight=w2,activation=1)\n",
    "    model.edges[node1,node2]['activation'] = 0\n",
    "    \n",
    "    model.edges[node1,new_node]['inn_num'] = inn_num((node1,new_node),num_models,max_inn_num)\n",
    "    model.edges[new_node,node2]['inn_num'] = inn_num((new_node,node2),num_models,max_inn_num)\n",
    "    \n",
    "    #save model\n",
    "    write_graph(model,model_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weight(model,model_num):\n",
    "    for edge in model.edges():\n",
    "        if(random.random()<.1):\n",
    "            #change weight\n",
    "            weight = nx.get_edge_attributes(model,'weight').get(edge)\n",
    "            model.edges[edge[0], edge[1]]['weight'] = random.random()\n",
    "        else:\n",
    "            #perturb weight\n",
    "            weight = nx.get_edge_attributes(model,'weight').get(edge)\n",
    "            model.edges[edge[0], edge[1]]['weight'] = model.edges[edge[0], edge[1]]['weight'] + random.random()*.2            \n",
    "    write_graph(model,model_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Innovation numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inn_num(edge,num_models,max_inn_num):\n",
    "    #check if edge exists, if it does, set edge innovation number to match\n",
    "    for model_num in range(num_models):\n",
    "        model = read_graph(model_num,num_inp,num_out) \n",
    "        temp_dict = nx.get_edge_attributes(model,'inn_num')\n",
    "        if edge in temp_dict.keys():\n",
    "            return temp_dict[edge]\n",
    "    \n",
    "    #if new edge, then return current unused max innovation number\n",
    "    max_inn_num[0]+=1\n",
    "    return max_inn_num[0]-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error in here\n",
    "#not all nodes are being calculated always\n",
    "def get_tf_model(model,num_inp,num_out):\n",
    "    #Create calc_dict of input nodes\n",
    "    calc_dict = {}\n",
    "    for i in range(num_inp): calc_dict[i]=tf.placeholder(tf.float32,[1])\n",
    "\n",
    "    #all nodes will be calculated after n steps, where n = number of uncalc nodes\n",
    "    for repeat in range(len(model.nodes())):\n",
    "\n",
    "        #get dictionary of uncalculated nodes\n",
    "        temp_uncalc_nodes = {}\n",
    "        for i in model.nodes():\n",
    "            if(i not in calc_dict):\n",
    "                temp_uncalc_nodes[i] = 0\n",
    "\n",
    "        for node in temp_uncalc_nodes:\n",
    "            #get all uncalc edges that point to current node\n",
    "            temp_list = [i for i in model.edges() if i[0] not in calc_dict and i[1] == node]\n",
    "            \n",
    "            #if list is empty, then we can calculate it\n",
    "            if(len(temp_list)==0):\n",
    "                #get all edges that point to current node\n",
    "                temp_list = [i for i in model.edges() if i[1] == node]\n",
    "                \n",
    "                #sum over all edge weight multiplied by the child nodes output\n",
    "                tensor_sum = tf.zeros([1],dtype=tf.float32)\n",
    "                for cur_edge in temp_list:\n",
    "                    weight = nx.get_edge_attributes(model,'weight').get(cur_edge)\n",
    "                    weight = tf.constant(weight,dtype=tf.float32)\n",
    "                    \n",
    "                    activation = nx.get_edge_attributes(model,'activation').get(cur_edge)\n",
    "                    activation = tf.constant(activation,dtype=tf.float32)\n",
    "                    \n",
    "                    node_output = calc_dict[cur_edge[0]]\n",
    "                    tensor_sum = node_output*weight*activation + tensor_sum\n",
    "                    \n",
    "                #add calculated node to calc_dict and remove node from uncalc_node dict\n",
    "                #break prevents for loop error since uncalc_nodes is changing\n",
    "                #calc_dict[node] = tf.nn.sigmoid(tensor_sum)\n",
    "                calc_dict[node] = tf.math.tanh(tensor_sum)\n",
    "                del temp_uncalc_nodes[node]\n",
    "                break\n",
    "                \n",
    "    #return list of output nodes\n",
    "    #not all output nodes are accounted for and are missing in calc_dict\n",
    "    out_list = []\n",
    "    #print(\"{} to {} with: {}\".format(num_inp,num_inp+num_out,calc_dict))\n",
    "    for i in range(num_inp,num_inp+num_out):\n",
    "        #if((i not in calc_dict) and (i<num_inp+num_out)):\n",
    "        #    out_list.append(.5)\n",
    "        #    calc_dict[i] = .5\n",
    "        #    out_list.append(calc_dict[i])\n",
    "        if(i not in calc_dict):\n",
    "            print(\"\\n\")\n",
    "            print(calc_dict)\n",
    "            print(\"\\n\")\n",
    "            print(i)\n",
    "            print(\"\\n\")\n",
    "            print(model.edges())\n",
    "            print(\"\\n\")\n",
    "            print(temp_uncalc_nodes)\n",
    "            print(\"\\n\")\n",
    "            print(len(model.nodes()))\n",
    "            print(\"\\n\")\n",
    "        else:\n",
    "            out_list.append(calc_dict[i])\n",
    "\n",
    "    return out_list,calc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speciate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem with c2 here\n",
    "def speciate(dict_rew_list,num_models,c1,c2,c3):\n",
    "    threshold = 5\n",
    "    max_species = 0\n",
    "    \n",
    "    #double for loop, \n",
    "    #create list of model_numbers with the same species\n",
    "    #[ [0,1,2,3], [4], [5,6,7,8], [9]]   Here, there are 4 species with 10 networks\n",
    "    used_model_num_list = [i for i in range(num_models)]\n",
    "    spec_list = [[(dict_rew_list[0],0)]] #initialized with the first model in its own species\n",
    "    max_species = 0\n",
    "    for model_num2 in used_model_num_list:\n",
    "        found_species = False\n",
    "        for species in spec_list:\n",
    "            model_num1 = species[0][1]\n",
    "            #if model number are the same, skip\n",
    "            if(model_num1 == model_num2):\n",
    "                found_species = True\n",
    "                break\n",
    "            \n",
    "            #read the two models and calculate the difference\n",
    "            gene_model1 = read_graph(model_num1,num_inp,num_out)\n",
    "            gene_model2 = read_graph(model_num2,num_inp,num_out)\n",
    "            diff = model_dif(gene_model1,gene_model2,c1,c2,c3)\n",
    "            \n",
    "            #if difference is below threshold, set model1 species to model2 species\n",
    "            if(diff < threshold):\n",
    "                #find graph in species lists\n",
    "                species.append((dict_rew_list[model_num2],model_num2))\n",
    "                found_species = True\n",
    "                break\n",
    "        if(found_species==False):\n",
    "            spec_list.append([(dict_rew_list[model_num2],model_num2)])\n",
    "            \n",
    "    return spec_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(reward_list,num_models,max_inn_num,keep_amt,c1,c2,c3):\n",
    "    #need to do speciation before deletion\n",
    "    temp_reward_list = [(sub[1], sub[0]) for sub in reward_list] \n",
    "    dict_rew_list = dict(temp_reward_list)\n",
    "    \n",
    "    #speciate\n",
    "    spec_list = speciate(dict_rew_list,num_models,c1,c2,c3)\n",
    "    print(len(spec_list))\n",
    "    \n",
    "    #adjust fitness\n",
    "    #get average reward of population\n",
    "    avg_rew = 0\n",
    "    for i in reward_list:\n",
    "        avg_rew += i[0]\n",
    "    avg_rew = avg_rew\n",
    "    \n",
    "    #get number of graphs per species\n",
    "    num_children_list = []\n",
    "    for spec in spec_list:\n",
    "        per_children = 0\n",
    "        for model_rew,model_num in spec:\n",
    "            per_children += model_rew\n",
    "            \n",
    "        per_children = per_children/avg_rew\n",
    "        num_children_list.append(per_children)\n",
    "  \n",
    "    #call delete graphs\n",
    "    del_amt = int((1-keep_amt)*num_models)\n",
    "    unused_model_num_list,used_model_num_list,del_rew_list = del_graphs(temp_reward_list,num_models,del_amt,spec_list,num_children_list)   \n",
    "    \n",
    "    unused_model_num_list.sort()\n",
    "    used_model_num_list.sort()\n",
    "    \n",
    "    #crossover\n",
    "    new_num_models = len(used_model_num_list)\n",
    "    while(len(unused_model_num_list)>0):\n",
    "        #choose two random and different indeces\n",
    "        rand_ind1 = random.randint(0,len(used_model_num_list)-1)\n",
    "        rand_ind2 = choice([i for i in range(0,len(used_model_num_list)-1) if i not in [rand_ind1]])\n",
    "        \n",
    "        #get model numbers\n",
    "        model_num1 = used_model_num_list[rand_ind1]\n",
    "        model_num2 = used_model_num_list[rand_ind2]\n",
    "        \n",
    "        #get models from model numbers        \n",
    "        gene_model1 = read_graph(model_num1,num_inp,num_out)        \n",
    "        gene_model2 = read_graph(model_num2,num_inp,num_out)\n",
    "        \n",
    "        #get new child model, write model, and pop used model number from list\n",
    "        for model_num2 in range(del_amt,num_models):\n",
    "            child_gene_model = get_child_gene_model(gene_model1,gene_model2,num_models,max_inn_num)\n",
    "            #need to get innovation number of child gene\n",
    "            \n",
    "            write_graph(child_gene_model,unused_model_num_list[0])\n",
    "            added_num = unused_model_num_list.pop(0)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossover helper function (Delete models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_graphs(reward_list,num_models,del_amt,spec_list,num_children_list):\n",
    "    unused_model_num_list = []\n",
    "    used_model_num_list = []\n",
    "    del_rew_list = []\n",
    "    path = os.getcwd()+\"\\\\Graph_folder\\\\\"\n",
    "    \n",
    "    spec_count = -1\n",
    "    for perc in num_children_list:\n",
    "        spec_count+=1\n",
    "        spec_del_amt = int(perc*del_amt)\n",
    "        spec_rew_list = spec_list[spec_count]\n",
    "        spec_rew_list.sort()\n",
    "        model_count = -1\n",
    "        for i in spec_list[spec_count]:\n",
    "            model_count+=1\n",
    "            if(model_count < spec_del_amt):\n",
    "                os.remove(path+\"model_\"+str(spec_rew_list[model_count][1])+\".edgelist\")     \n",
    "                unused_model_num_list.append(spec_rew_list[model_count][1])\n",
    "            else:\n",
    "                used_model_num_list.append(spec_rew_list[model_count][1])\n",
    "                del_rew_list.append(spec_rew_list[model_count])\n",
    "\n",
    "    return unused_model_num_list,used_model_num_list,del_rew_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get child model given parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_child_gene_model(gene_model1,gene_model2,num_models,max_inn_num):\n",
    "    act_prob = .7\n",
    "    child_model = nx.DiGraph()\n",
    "    \n",
    "    #get attributes of each parent graph\n",
    "    weight_dict1 = nx.get_edge_attributes(gene_model1,'weight')\n",
    "    weight_dict2 = nx.get_edge_attributes(gene_model2,'weight')\n",
    "    act_dict1 = nx.get_edge_attributes(gene_model1,'activation')\n",
    "    act_dict2 = nx.get_edge_attributes(gene_model2,'activation')\n",
    "    inn_dict1 = nx.get_edge_attributes(gene_model1,'inn_num')\n",
    "    inn_dict2 = nx.get_edge_attributes(gene_model2,'inn_num')\n",
    "    \n",
    "    #loop over first parent to see if nodes \n",
    "    for edge in weight_dict1:\n",
    "        #if edge is in both models, 50% chance to choose either\n",
    "        weight = 0\n",
    "        activation = 1\n",
    "        innovation = 0\n",
    "        if(edge in weight_dict2):\n",
    "            if(random.random() < .5):\n",
    "                weight = weight_dict1.get(edge)\n",
    "                activation = act_dict1.get(edge)\n",
    "                innovation = inn_dict1.get(edge)\n",
    "            else:\n",
    "                weight = weight_dict2.get(edge)\n",
    "                activation = act_dict2.get(edge)\n",
    "                innovation = inn_dict2.get(edge)\n",
    "        else:\n",
    "            weight = weight_dict1.get(edge)\n",
    "            activation = act_dict1.get(edge)\n",
    "            innovation = inn_dict1.get(edge)\n",
    "            \n",
    "        #set activation to 1 with probability\n",
    "        if(activation == 0):\n",
    "            if(random.random()<act_prob):\n",
    "                activation = 1\n",
    "                \n",
    "        if(check_edges(child_model,edge[0],edge[1])):\n",
    "            child_model.add_edge(edge[0],edge[1],weight=weight,activation=activation,inn_num=innovation)\n",
    "        \n",
    "    for edge in weight_dict2:\n",
    "        #if edge is in both models, 50% chance to choose either\n",
    "        if(edge not in weight_dict1):\n",
    "            weight = 0\n",
    "            activation = 1\n",
    "            weight = weight_dict2.get(edge)\n",
    "            activation = act_dict2.get(edge)\n",
    "            innovation = inn_dict2.get(edge)\n",
    "            \n",
    "        #set activation to 1 with probability\n",
    "        if(activation == 0):\n",
    "            if(random.random()<act_prob):\n",
    "                activation = 1\n",
    "            \n",
    "        if(check_edges(child_model,edge[0],edge[1])):\n",
    "            child_model.add_edge(edge[0],edge[1],weight=weight,activation=activation,inn_num=innovation)  \n",
    "    return child_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dif(gene_model1,gene_model2,c1,c2,c3):\n",
    "    delta_sum = 0\n",
    "    num_disjoint = 1\n",
    "    num_excess = 1\n",
    "    num_weights = 1\n",
    "    weight_sum = 0\n",
    "    \n",
    "    temp_dict1 = nx.get_edge_attributes(gene_model1,'weight')\n",
    "    temp_dict2 = nx.get_edge_attributes(gene_model2,'weight')\n",
    "    for edge in temp_dict1:\n",
    "        if(edge in temp_dict2):\n",
    "            #weight difference\n",
    "            num_weights+=1\n",
    "            weight1 = nx.get_edge_attributes(gene_model1,'weight').get(edge)\n",
    "            weight2 = nx.get_edge_attributes(gene_model2,'weight').get(edge)\n",
    "            weight_sum += abs(weight2-weight1)\n",
    "        else:\n",
    "            # disjoint\n",
    "            num_disjoint+=1\n",
    "    \n",
    "    for edge in temp_dict2:\n",
    "        #excess\n",
    "        if(edge not in temp_dict1):\n",
    "            num_disjoint+=1\n",
    "        \n",
    "    delta_sum = (c1*num_excess)/(num_excess + num_disjoint) + (c2*num_disjoint)/(num_excess + num_disjoint) + (c3*weight_sum)/num_weights\n",
    "    return delta_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for loops in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_edges(model,node1,node2):\n",
    "    if((node2,node1) in model.edges() or (node1,node2) in model.edges()):\n",
    "        return False\n",
    "            \n",
    "    temp_model = model.copy()\n",
    "    temp_model.add_edge(node1,node2,weight=random.randrange(-2,2))\n",
    "    \n",
    "    try:\n",
    "        #if model has cycles, switch node1 and node2\n",
    "        nx.find_cycle(temp_model, orientation='original')\n",
    "    except:\n",
    "        #model.add_edge(node1,node2,weight=random.random(),activation=1,inn_num=inn_num((node1,node2),num_models,max_inn_num))\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inp = 24\n",
    "num_out = 4\n",
    "\n",
    "#num_inp = 4\n",
    "num_bias = 4\n",
    "num_inp = num_inp + num_bias\n",
    "#num_out = 1\n",
    "\n",
    "#changing num_models limits amount of saved models: fix this\n",
    "num_models = 100\n",
    "trials = 1\n",
    "num_game_steps = 100\n",
    "#max_inn_num = [num_inp+num_out]\n",
    "max_inn_num = [0]\n",
    "gens = 1\n",
    "\n",
    "c1 = 1.5\n",
    "c2 = 1.5\n",
    "c3 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raven\\anaconda3\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model num: 0\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "model num: 1\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "model num: 2\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "model num: 3\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "model num: 4\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "model num: 5\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "model num: 6\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "model num: 7\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "model num: 8\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "model num: 9\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-17861d9087b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m                     \u001b[0mfin_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                     \u001b[0mrun_model_time5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                     \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#this is what costs the most time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m                     \u001b[0mrun_model_time6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    958\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    959\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[1;31m# TODO(yuanbyu, keveman): Revisit whether we should just treat feeding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m     \u001b[1;31m# of a handle from a different device as an error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m     \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1175\u001b[0m     \u001b[0mfinal_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[0mfinal_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_update_with_movers\u001b[1;34m(self, feed_dict, feed_map)\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[0mhandle_movers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1418\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfeed_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1419\u001b[1;33m       \u001b[0mmover\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_handle_mover\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1420\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmover\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1421\u001b[0m         \u001b[0mhandle_movers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmover\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\session_ops.py\u001b[0m in \u001b[0;36m_get_handle_mover\u001b[1;34m(graph, feeder, handle)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_handle_mover\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m   \u001b[1;34m\"\"\"Return a move subgraph for this pair of feeder and handle.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m   \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_handle_feeder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\session_ops.py\u001b[0m in \u001b[0;36m_get_handle_feeder\u001b[1;34m(graph, feeder)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_handle_feeder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_feeders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeeder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mname\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2053\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2054\u001b[0m     \u001b[1;34m\"\"\"The full name of this operation.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2055\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2056\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2057\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_a = time.time()\n",
    "tf.reset_default_graph()\n",
    "env = gym.make('BipedalWalker-v3')\n",
    "#env = gym.make('MountainCar-v0')\n",
    "#env = gym.make('Acrobot-v1')\n",
    "#env = gym.make('MountainCarContinuous-v0')\n",
    "create_graphs(num_models,num_inp,num_out)\n",
    "generations = 20\n",
    "keep_amt = .1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for gen in range(generations):\n",
    "        total_a = time.time()\n",
    "\n",
    "        #empty reward\n",
    "        reward_list = []\n",
    "\n",
    "        #run over all models\n",
    "        for model_num in range(num_models):\n",
    "            #get model from file\n",
    "            gene_model = read_graph(model_num,num_inp,num_out)\n",
    "            print(\"model num: {}\".format(model_num))\n",
    "            print(gene_model.edges())\n",
    "            print(gene_model.nodes())\n",
    "            \n",
    "            #Mutation\n",
    "            mut_time1 = time.time()\n",
    "            mutate(gene_model,num_models,max_inn_num,model_num)\n",
    "            mut_time2 = time.time()\n",
    "\n",
    "            #get model from file after mutations\n",
    "            gene_model = read_graph(model_num,num_inp,num_out)\n",
    "\n",
    "            #turn gene model into tensorflow model\n",
    "            get_tf_time1 = time.time()\n",
    "            tf_outputs,calc_dict = get_tf_model(gene_model,num_inp,num_out)\n",
    "            get_tf_time2 = time.time()\n",
    "\n",
    "            full_sum = 0\n",
    "            for trial in range(1):\n",
    "                #get inputs\n",
    "                observation = env.reset()\n",
    "                observation = np.append(observation,[1])\n",
    "\n",
    "                #run model\n",
    "                run_model_time1 = time.time()\n",
    "                model_r_sum = 0\n",
    "                for game_steps in range(500):#num_game_steps):\n",
    "                    #set up feed dictionary for model input\n",
    "                    feed_dict = {}\n",
    "                    run_model_time3 = time.time()\n",
    "                    for i in range(len(observation)): feed_dict[calc_dict[i]] = [observation[i]]\n",
    "                    for i in range(len(observation),num_inp): feed_dict[calc_dict[i]] = [1.0] \n",
    "                    run_model_time4 = time.time()\n",
    "\n",
    "                    fin_out = []\n",
    "                    run_model_time5 = time.time()\n",
    "                    actions = sess.run(tf_outputs,feed_dict=feed_dict)  #this is what costs the most time\n",
    "                    run_model_time6 = time.time()\n",
    "                    \n",
    "                    run_model_time7 = time.time()\n",
    "                    for i in range(num_out):\n",
    "                        fin_out.append(actions[i][0])\n",
    "                    #action = fin_out.index(max(fin_out))\n",
    "                    run_model_time8 = time.time()\n",
    "                    \n",
    "                    #take action\n",
    "                    action = np.array(fin_out)\n",
    "                    \n",
    "                    run_model_time9 = time.time()\n",
    "                    observation, reward, done, info = env.step(action)\n",
    "                    run_model_time10 = time.time()\n",
    "\n",
    "                    #append reward\n",
    "\n",
    "                    model_r_sum+=reward\n",
    "                    if(done):\n",
    "                        run_model_time11 = time.time()\n",
    "                        env.close()\n",
    "                        run_model_time12 = time.time()\n",
    "                        break\n",
    "\n",
    "                full_sum+=model_r_sum\n",
    "                run_model_time2 = time.time()\n",
    "            reward_list.append((full_sum/trials,model_num))\n",
    "\n",
    "        #Crossover\n",
    "        #print(\"start crossover\")\n",
    "        #print(reward_list)\n",
    "        crossover(reward_list,num_models,max_inn_num,keep_amt,c1,c2,c3)\n",
    "        #print(\"end crossover\")\n",
    "\n",
    "        #calculate average reward\n",
    "        sum_rew = 0\n",
    "        for i in reward_list:\n",
    "            sum_rew+= i[0]\n",
    "        avg_rew = sum_rew/num_models\n",
    "        #reward_list.append(avg_rew)\n",
    "\n",
    "        total_b = time.time()\n",
    "        print(\"Generation: {} Average reward: {} Time: {} Highest Reward: {}\".format(gen,avg_rew,total_b-total_a,max(reward_list)))\n",
    "        print(\"mutation time: {}\".format(mut_time2-mut_time1))\n",
    "        print(\"get_tf: {}\".format(get_tf_time2-get_tf_time1))\n",
    "        print(\"run model: {}\".format(run_model_time2-run_model_time1))\n",
    "        print(\"run model: {}\".format(run_model_time4-run_model_time3))\n",
    "        print(\"run model: {}\".format(run_model_time6-run_model_time5))\n",
    "        print(\"run model: {}\".format(run_model_time8-run_model_time7))\n",
    "        print(\"run model: {}\".format(run_model_time10-run_model_time9))\n",
    "        #print(\"run model: {}\".format(run_model_time12-run_model_time11))\n",
    "\n",
    "\n",
    "\n",
    "    #if(gen == generations-1):\n",
    "    #    !mkdir -p saved_model\n",
    "    #    model.save('saved_model/my_model') \n",
    "sess.close()\n",
    "total_b = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixes some weird tensorflow error\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "#get model number\n",
    "#reward_list.sort(reverse=True)\n",
    "#model_num = reward_list[0][1]\n",
    "#print(model_num)\n",
    "model_num = 30\n",
    "\n",
    "#get model from file\n",
    "gene_model = read_graph(model_num,num_inp,num_out)\n",
    "\n",
    "\n",
    "#get model from file after mutations\n",
    "gene_model = read_graph(model_num,num_inp,num_out)\n",
    "\n",
    "#turn gene model into tensorflow model\n",
    "tf_outputs,calc_dict = get_tf_model(gene_model,num_inp,num_out)\n",
    "\n",
    "\n",
    "#get inputs\n",
    "observation = env.reset()\n",
    "observation = np.append(observation,[1])\n",
    "\n",
    "#run model\n",
    "with tf.Session() as sess:\n",
    "    for game_steps in range(500):#num_game_steps):\n",
    "        #set up feed dictionary for model input\n",
    "        feed_dict = {}\n",
    "        for i in range(len(observation)): feed_dict[calc_dict[i]] = [observation[i]]\n",
    "        for i in range(len(observation),num_inp): feed_dict[calc_dict[i]] = [1.0]\n",
    "\n",
    "        fin_out = []\n",
    "        actions = sess.run(tf_outputs,feed_dict=feed_dict)  #this is what costs the most time\n",
    "\n",
    "        for i in range(num_out):\n",
    "            fin_out.append(actions[i][0])\n",
    "\n",
    "        #take action\n",
    "        env.render()\n",
    "        action = np.array(fin_out)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "\n",
    "        if(done):\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
